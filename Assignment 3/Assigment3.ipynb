{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.filters import prewitt_h, prewitt_v\n",
    "from skimage.feature import hog\n",
    "\n",
    "train_files = []\n",
    "train_input = np.ndarray(shape=(50000, 4964))\n",
    "train_output = []\n",
    "\n",
    "test_files = []\n",
    "test_input = np.ndarray(shape=(10000, 4964))\n",
    "test_output = []\n",
    "\n",
    "def extract_features(file: str) -> np.ndarray:\n",
    "    image_array = np.ndarray(0)\n",
    "\n",
    "    img = imread(file)\n",
    "    image_array = np.append(image_array, np.asarray(img, dtype=int).reshape(1024*3))\n",
    "    # print(image_array.reshape((1024, 3)).shape)\n",
    "\n",
    "    # image = imread(file, as_gray=True)\n",
    "    # edges_horizontal = prewitt_h(image)\n",
    "    # edges_vertical = prewitt_v(image)\n",
    "    # image_array = np.append(image_array, edges_horizontal)\n",
    "    # image_array = np.append(image_array, edges_vertical)\n",
    "\n",
    "    # image = cv2.imread(file)\n",
    "    # background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    # foreground_mask = background_subtractor.apply(image)\n",
    "    # image_array = np.append(image_array, np.asarray(foreground_mask[:,:], dtype=int))\n",
    "\n",
    "    img = cv2.imread(file)\n",
    "    gray_img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, descriptors = sift.detectAndCompute((gray_img).astype(\"uint8\"), None)\n",
    "    # image_array = np.append(image_array, np.asarray(keypoints))\n",
    "    # image_array = np.append(image_array, np.asarray(descriptors))\n",
    "    if descriptors is None:\n",
    "        image_array = np.append(image_array, np.zeros((128,)))\n",
    "    else:\n",
    "        image_array = np.append(image_array, np.mean(descriptors, axis=0))\n",
    "\n",
    "    winSize = (64,64)\n",
    "    blockSize = (16,16)\n",
    "    blockStride = (8,8)\n",
    "    cellSize = (8,8)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = 4.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 2.0000000000000001e-01\n",
    "    gammaCorrection = 0\n",
    "    nlevels = 64\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "                        histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "    #compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
    "    winStride = (8,8)\n",
    "    padding = (8,8)\n",
    "    locations = ((10,20),)\n",
    "    hist = hog.compute(img,winStride,padding,locations)\n",
    "    image_array = np.append(image_array, np.asarray(hist))\n",
    "\n",
    "    # img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # s = img_hsv[:, :, 1]\n",
    "    # s = np.where(s < 100, 0, 1)\n",
    "    # v = (img_hsv[:, :, 2]+127) % 255\n",
    "    # v = np.where(v>127, 1, 0)\n",
    "    # foreground = np.where(s+v > 0, 1, 0).astype(np.uint8)\n",
    "    # background  = np.where(foreground==0, 255, 0).astype(np.uint8)\n",
    "    # background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)\n",
    "    # foreground = cv2.bitwise_and(img, img, mask=foreground)\n",
    "    # image_array = np.append(image_array, np.asarray(background))\n",
    "    # image_array = np.append(image_array, np.asarray(foreground))\n",
    "\n",
    "    # blur_img = cv2.GaussianBlur(gray_img, (3, 3), 0)\n",
    "    # # sobelx = cv2.Sobel(src=blur_img, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5)\n",
    "    # # sobely = cv2.Sobel(src=blur_img, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5)\n",
    "    # # sobelxy = cv2.Sobel(src=blur_img, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5)\n",
    "    # edges = cv2.Canny(blur_img, 100, 200)\n",
    "    # image_array = np.append(image_array, np.asarray(edges))\n",
    "\n",
    "    # dst = cv2.cornerHarris(gray_img, 2, 3, 0.04)\n",
    "    # image_array = np.append(image_array, np.asarray(dst))\n",
    "\n",
    "    # img = imread(file, as_gray=True)\n",
    "    # img_hog, img_hog_img = hog(\n",
    "    # img, pixels_per_cell=(14,14), \n",
    "    # cells_per_block=(2, 2), \n",
    "    # orientations=9, \n",
    "    # visualize=True, \n",
    "    # block_norm='L2-Hys')\n",
    "    # image_array = np.append(image_array, img_hog)\n",
    "    return image_array\n",
    "\n",
    "with open(\"images/train.csv\") as trainFile:\n",
    "    reader = csv.reader(trainFile)\n",
    "    for (row_no, row) in enumerate(reader):\n",
    "        if row_no == 0:\n",
    "            continue\n",
    "        else:\n",
    "            train_files.append(\"images/train/\"+row[0])\n",
    "            train_output.append(row[1])\n",
    "\n",
    "for (i, file) in enumerate(train_files):\n",
    "    train_input[i] = extract_features(file)\n",
    "\n",
    "with open(\"images/test.csv\") as testFile:\n",
    "    reader = csv.reader(testFile)\n",
    "    for (row_no, row) in enumerate(reader):\n",
    "        if row_no == 0:\n",
    "            continue\n",
    "        else:\n",
    "            test_files.append(\"images/test/\"+row[0])\n",
    "            test_output.append(row[1])\n",
    "\n",
    "for (i, file) in enumerate(test_files):\n",
    "    test_input[i] = extract_features(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# random_indices = random.sample(range(50000), 3000)\n",
    "\n",
    "# estimator_KNN = KNeighborsClassifier(algorithm='auto')\n",
    "\n",
    "# parameters_KNN = {\n",
    "#     'n_neighbors': (1,10, 1),\n",
    "#     'leaf_size': (20,40,1),\n",
    "#     'p': (1,2),\n",
    "#     'weights': ('uniform', 'distance'),\n",
    "#     'metric': ('minkowski', 'chebyshev'),\n",
    "# }\n",
    "\n",
    "# grid_search_KNN = GridSearchCV(estimator=estimator_KNN, param_grid=parameters_KNN, scoring='accuracy', n_jobs=2, cv=5)\n",
    "# grid_search_KNN.fit(train_input[:50000], train_output).predict(test_input)\n",
    "# print(grid_search_KNN.best_params_)\n",
    "# print(grid_search_KNN.best_score_)\n",
    "\n",
    "pipe1 = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=2, weights=\"distance\", n_jobs=5))]).fit(train_input[:50000], train_output)\n",
    "# pipe2 = Pipeline([(\"scaler\", StandardScaler()), (\"svm\", LinearSVC(C=1))]).fit(train_input[:40000], train_output[:40000])\n",
    "# pipe3 = Pipeline([(\"adaBoost\", AdaBoostClassifier())]).fit(train_input[:5000], train_output[:5000])\n",
    "\n",
    "classifier = pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ys, ys_pred):\n",
    "    # assert ys.shape == ys_pred.shape\n",
    "    # assert ys.ndim == 1\n",
    "    return np.sum(ys == ys_pred) / len(ys)\n",
    "\n",
    "get_accuracy(train_output[40001:50000], classifier.predict(train_input[40001:50000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = \"images/test\"\n",
    "suffix = 1\n",
    "extension = \".csv\"\n",
    "\n",
    "while os.path.exists(filename+str(suffix)+extension):\n",
    "    suffix += 1\n",
    "\n",
    "filepath = filename+str(suffix)+extension\n",
    "\n",
    "with open(filepath, 'w') as outputFile:\n",
    "    fieldNames = [\"im_name\", \"label\"]\n",
    "    writer = csv.DictWriter(outputFile, fieldnames=fieldNames)\n",
    "    writer.writeheader()\n",
    "\n",
    "with open(filepath, 'w') as outputFile:\n",
    "    fieldNames = [\"im_name\", \"label\"]\n",
    "    writer = csv.DictWriter(outputFile, fieldnames=fieldNames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i, label in enumerate(classifier.predict(test_input)[:10000]):\n",
    "        writer.writerow({\"im_name\": test_files[i].split(\"/\")[2], \"label\": label})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP3314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
